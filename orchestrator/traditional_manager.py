"""
TRADITIONAL MANAGER - CENTRALIZED INTEGRATION VERSION

UPDATED VERSION - ELIMINATES DUPLICATION + FIXES PARAMETER WARNINGS:
- FIXED: Added async_client_manager parameter to eliminate parameter mismatch warnings
- Removed duplicate PromptAssembler integration  
- Uses centralized NLP-Schema Integration Bridge for prompt generation
- Maintains all performance optimizations and caching
- Eliminates code duplication with other orchestrator files

Author: Enhanced for Performance & Accuracy (Updated for Centralized Architecture + Parameter Fix)
Version: 2.1.1 - PARAMETER MISMATCH WARNINGS FIXED
Date: 2025-08-19
"""

import logging
import asyncio
import time
from typing import Optional, Dict, Any, List
from dataclasses import dataclass
import json
import hashlib

from agent.schema_searcher.engines.chroma_engine import ChromaEngine
from agent.schema_searcher.utils.adapter_helpers import search_results_to_schema_context
# REMOVED: from agent.prompt_builder.assemblers.prompt_assembler import PromptAssembler
from agent.sql_generator.generator import SQLGenerator
from agent.sql_executor.executor import SQLExecutor

logger = logging.getLogger(__name__)

@dataclass
class TraditionalManagerConfig:
    """Configuration for Traditional Manager"""
    max_processing_time: float = 15.0
    enable_nlp_enhancement: bool = True
    enable_caching: bool = True
    cache_ttl: int = 300  # 5 minutes
    max_schema_results: int = 30  # Limit for performance
    concurrent_limit: int = 10
    enable_performance_monitoring: bool = True

class TraditionalManager:
    """
    CENTRALIZED TRADITIONAL MANAGER - NO DUPLICATION + PARAMETER WARNINGS FIXED
    
    CHANGES MADE:
     FIXED: Added async_client_manager parameter to eliminate warnings
     Removed duplicate PromptAssembler initialization
     Uses centralized NLP-Schema Integration Bridge  
     Eliminates prompt assembly duplication
     Maintains all performance optimizations
     Preserves caching and fast processing
    """

    def __init__(self, 
                 config: Optional[TraditionalManagerConfig] = None, 
                 nlp_schema_bridge=None, 
                 async_client_manager=None):  # ðŸ”§ FIXED: Added missing parameter
        """Initialize Traditional Manager with centralized bridge integration"""
        self.config = config or TraditionalManagerConfig()
        self.nlp_schema_bridge = nlp_schema_bridge  # CENTRALIZED: Use shared bridge
        self.async_client_manager = async_client_manager  # ðŸ”§ FIXED: Store AsyncClientManager
        
        # Initialize core components (keeping non-duplicated ones)
        self.schema_engine = ChromaEngine()
        # REMOVED: self.prompt_assembler = PromptAssembler()  # Using centralized bridge instead
        
        # ðŸ”§ FIXED: Initialize SQL Generator with AsyncClientManager if available
        if self.async_client_manager:
            self.sql_generator = SQLGenerator(async_client_manager=self.async_client_manager) # pyright: ignore[reportCallIssue]
            logger.info("SQL Generator initialized with shared AsyncClientManager")
        else:
            self.sql_generator = SQLGenerator()
            logger.info("SQL Generator initialized without AsyncClientManager")
            
        self.sql_executor = SQLExecutor()
        
        # Performance optimization (kept - not duplicated)
        self.cache = {}  # Query cache
        self.performance_stats = {
            "total_queries": 0,
            "cache_hits": 0,
            "successful_queries": 0,
            "failed_queries": 0,
            "average_processing_time": 0.0,
            "nlp_enhanced_queries": 0
        }
        
        logger.info("=" * 80)
        logger.info("TRADITIONAL MANAGER - CENTRALIZED ARCHITECTURE v2.1.1")
        logger.info("âœ… No duplicate PromptAssembler - uses centralized bridge")
        logger.info("âœ… Optimized for fast processing of simple queries")
        logger.info("âœ… Enhanced caching and performance monitoring")
        logger.info(f"âœ… AsyncClientManager: {'Available' if async_client_manager else 'Not provided'}")
        logger.info("=" * 80)

    async def process_query(
        self, 
        user_query: str, 
        enhanced_context: Optional[Dict[str, Any]] = None,
        request_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        CENTRALIZED: Main processing method using centralized prompt generation
        """
        self.performance_stats["total_queries"] += 1
        start_time = time.time()
        request_id = request_id or f"trad_{int(start_time)}"

        logger.info(f"[{request_id}] Processing query: {user_query[:100]}")
        logger.info(f"[{request_id}] Bridge Available: {'Yes' if self.nlp_schema_bridge else 'No'}")
        logger.info(f"[{request_id}] AsyncClientManager: {'Available' if self.async_client_manager else 'Not provided'}")

        try:
            # 1. PERFORMANCE: Check cache first
            cache_key = self._generate_cache_key(user_query, enhanced_context)
            cached_result = self._get_cached_result(cache_key)
            if cached_result:
                self.performance_stats["cache_hits"] += 1
                logger.debug(f"[{request_id}] Cache hit - returning cached result")
                return self._add_metadata(cached_result, start_time, request_id, cached=True)

            # 2. ACCURACY: Extract NLP insights for focused search
            search_filters = self._extract_search_filters(enhanced_context)
            
            # 3. PERFORMANCE: Fast schema search with NLP filtering
            schema_results = await self._perform_optimized_schema_search(
                user_query, search_filters, request_id
            )

            # 4. ACCURACY: Convert results to enriched schema context
            schema_context = self._build_enriched_schema_context(
                schema_results, enhanced_context
            )

            # 5. CENTRALIZED PROMPT GENERATION - Use bridge instead of duplicate PromptAssembler
            prompt = await self._generate_optimized_prompt_centralized(
                user_query, schema_context, request_id
            )

            # 6. ACCURACY: Generate SQL with enhanced context
            sql_result = await self._generate_enhanced_sql(
                prompt, schema_context, enhanced_context, request_id
            )

            # 7. PERFORMANCE: Prepare and cache result
            final_result = self._build_final_result(
                user_query, sql_result, schema_context, enhanced_context, start_time
            )
            
            self._cache_result(cache_key, final_result)
            self.performance_stats["successful_queries"] += 1
            
            if enhanced_context:
                self.performance_stats["nlp_enhanced_queries"] += 1

            logger.info(f"[{request_id}] Query processed successfully in {final_result['processing_time']:.3f}s")
            logger.info(f"[{request_id}] Prompt Source: {'Centralized Bridge' if self.nlp_schema_bridge else 'Fallback'}")
            return self._add_metadata(final_result, start_time, request_id)

        except Exception as e:
            self.performance_stats["failed_queries"] += 1
            logger.error(f"[{request_id}] Query processing failed: {e}")
            
            return {
                "success": False,
                "error": str(e),
                "query": user_query,
                "request_id": request_id,
                "processing_time": time.time() - start_time,
                "manager": "traditional"
            }

    def _extract_search_filters(self, enhanced_context: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """Extract search optimization filters from NLP context"""
        filters = {}
        
        if not enhanced_context or not self.config.enable_nlp_enhancement:
            return filters

        # Extract NLP optimization data
        nlp_optimization = enhanced_context.get('nlp_optimization', {})
        
        # Focus on predicted tables and columns
        if 'key_entities' in nlp_optimization:
            filters['focus_entities'] = nlp_optimization['key_entities'][:5]  # Limit for performance
        
        # Use simplified intent for faster processing
        if 'simplified_intent' in nlp_optimization:
            filters['intent'] = nlp_optimization['simplified_intent']
        
        # Apply fast processing hint
        if nlp_optimization.get('fast_processing'):
            filters['max_results'] = min(self.config.max_schema_results, 20)  # Even more limited
        
        return filters

    async def _perform_optimized_schema_search(
        self, 
        query: str, 
        filters: Dict[str, Any], 
        request_id: str
    ) -> List[Any]:
        """Perform optimized schema search with NLP filtering"""
        try:
            logger.debug(f"[{request_id}] Performing optimized schema search")
            
            # Prepare search parameters for performance
            search_params = {
                'max_results': filters.get('max_results', self.config.max_schema_results)
            }
            
            # Add entity focusing if available
            if 'focus_entities' in filters:
                search_params['focus_entities'] = filters['focus_entities']
            
            # Execute search with timeout for performance
            search_results = await asyncio.wait_for(
                asyncio.get_event_loop().run_in_executor(
                    None,
                    lambda: asyncio.run(self.schema_engine.search(query, **search_params)) # pyright: ignore[reportArgumentType]
                ),
                timeout=5.0  # Fast timeout for simple queries
            )
            
            logger.debug(f"[{request_id}] Schema search returned {len(search_results)} results")
            return search_results

        except asyncio.TimeoutError:
            logger.warning(f"[{request_id}] Schema search timed out, using fallback")
            return []
        except Exception as e:
            logger.error(f"[{request_id}] Schema search failed: {e}")
            return []

    def _build_enriched_schema_context(
        self, 
        schema_results: List[Any], 
        enhanced_context: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Build enriched schema context for accurate prompt generation"""
        try:
            # Convert search results using adapter
            schema_context = search_results_to_schema_context(schema_results)
            
            # Enrich with NLP insights for accuracy
            if enhanced_context and self.config.enable_nlp_enhancement:
                schema_context['nlp_insights'] = { # pyright: ignore[reportIndexIssue]
                    'intent': enhanced_context.get('nlp_optimization', {}).get('simplified_intent', 'simple_lookup'),
                    'entities': enhanced_context.get('nlp_optimization', {}).get('key_entities', []),
                    'fast_processing': enhanced_context.get('nlp_optimization', {}).get('fast_processing', True)
                }
            
            # Add performance optimization hints
            schema_context['optimization_hints'] = { # pyright: ignore[reportIndexIssue]
                'query_type': 'simple',
                'processing_mode': 'fast',
                'result_limit': self.config.max_schema_results
            }
            
            return schema_context # pyright: ignore[reportReturnType]

        except Exception as e:
            logger.warning(f"Schema context building failed: {e}, using fallback")
            return {"tables": [], "columns": [], "optimization_hints": {"processing_mode": "fallback"}}

    async def _generate_optimized_prompt_centralized(
        self, 
        query: str, 
        schema_context: Dict[str, Any], 
        request_id: str
    ) -> str:
        """
        CENTRALIZED: Use bridge for prompt generation instead of duplicate PromptAssembler
        """
        try:
            if self.nlp_schema_bridge:
                logger.debug(f"[{request_id}] Using centralized PromptBuilder via bridge")
                
                # Use centralized prompt generation service
                prompt_result = await self.nlp_schema_bridge.generate_sophisticated_prompt_for_manager(
                    query,
                    schema_context,
                    "traditional",  # Manager type
                    request_id
                )
                
                if prompt_result.get('success'):
                    sophisticated_prompt = prompt_result.get('prompt', '')
                    
                    logger.debug(f"[{request_id}] Centralized prompt generation successful: "
                               f"quality={prompt_result.get('quality', 'unknown')}, "
                               f"length={len(sophisticated_prompt)} chars")
                    
                    return sophisticated_prompt
                else:
                    logger.warning(f"[{request_id}] Centralized prompt generation failed: {prompt_result.get('error', 'unknown')}")
            
            # Fallback to simple prompt generation
            logger.warning(f"[{request_id}] Using fallback prompt generation")
            return self._build_fallback_prompt(query, schema_context)
            
        except Exception as e:
            logger.warning(f"[{request_id}] Prompt generation failed: {e}, using fallback")
            return self._build_fallback_prompt(query, schema_context)

    def _build_fallback_prompt(self, query: str, schema_context: Dict[str, Any]) -> str:
        """Build simple fallback prompt for reliability when centralized bridge unavailable"""
        tables = schema_context.get('tables', [])
        columns = schema_context.get('columns', [])
        
        prompt_parts = [
            f"Generate simple SQL for traditional query: {query}",
            "",
            "TRADITIONAL MANAGER CONTEXT:"
        ]
        
        # Add basic schema information
        if tables:
            prompt_parts.append(f"Available tables: {', '.join(tables[:5])}")
        else:
            prompt_parts.append("No tables specified")
            
        if columns:
            prompt_parts.append(f"Key columns: {', '.join(columns[:10])}")
        else:
            prompt_parts.append("No columns specified")
        
        # Add NLP insights if available
        nlp_insights = schema_context.get('nlp_insights', {})
        if nlp_insights:
            prompt_parts.extend([
                "",
                "NLP INSIGHTS:",
                f"- Intent: {nlp_insights.get('intent', 'simple_lookup')}",
                f"- Entities: {', '.join(nlp_insights.get('entities', [])[:3])}",
                f"- Fast Processing: {nlp_insights.get('fast_processing', True)}"
            ])
        
        # Add traditional manager specific instructions
        prompt_parts.extend([
            "",
            "TRADITIONAL PROCESSING INSTRUCTIONS:",
            "- Focus on simple, efficient query generation",
            "- Optimize for performance and speed",
            "- Use straightforward SQL constructs",
            "- Avoid complex joins or subqueries unless necessary"
        ])
        
        return "\n".join(prompt_parts)

    async def _generate_enhanced_sql(
        self, 
        prompt: str, 
        schema_context: Dict[str, Any],
        enhanced_context: Optional[Dict[str, Any]], 
        request_id: str
    ) -> Dict[str, Any]:
        """Generate SQL with enhanced accuracy using NLP context"""
        try:
            logger.debug(f"[{request_id}] Generating enhanced SQL")
            
            # Prepare enhanced generation context
            generation_context = {
                'schema_context': schema_context,
                'nlp_context': enhanced_context.get('nlp_optimization', {}) if enhanced_context else {},
                'processing_mode': 'traditional_fast'
            }
            
            # Generate SQL with timeout
            sql_result = await asyncio.wait_for(
                asyncio.get_event_loop().run_in_executor(
                    None,
                    lambda: self.sql_generator.generate_sql(
                        prompt=prompt,
                        context=generation_context
                    )
                ),
                timeout=8.0  # Reasonable timeout for SQL generation
            )
            
            # Validate result
            if not sql_result or not sql_result.get("generated_sql"):
                raise ValueError("Empty SQL result")
            
            return sql_result

        except Exception as e:
            logger.warning(f"[{request_id}] SQL generation failed: {e}, using fallback")
            return {
                "success": False,
                "generated_sql": f"-- SQL generation failed for: {prompt[:50]}...",
                "confidence": 0.3,
                "model": "fallback",
                "error": str(e)
            }

    def _build_final_result(
        self, 
        query: str, 
        sql_result: Dict[str, Any],
        schema_context: Dict[str, Any],
        enhanced_context: Optional[Dict[str, Any]],
        start_time: float
    ) -> Dict[str, Any]:
        """Build final result with comprehensive metadata"""
        return {
            "success": sql_result.get("success", True),
            "query": query,
            "generated_sql": sql_result.get("generated_sql", ""),
            "confidence": sql_result.get("confidence", 0.8),
            "model_used": sql_result.get("model", "traditional"),
            "processing_time": time.time() - start_time,
            
            # Performance metadata
            "performance": {
                "manager_used": "traditional",
                "nlp_enhanced": bool(enhanced_context),
                "schema_tables_found": len(schema_context.get('tables', [])),
                "schema_columns_found": len(schema_context.get('columns', [])),
                "processing_mode": "optimized",
                "centralized_prompt_builder": self.nlp_schema_bridge is not None,
                "async_client_manager_available": self.async_client_manager is not None  # ðŸ”§ NEW: Added tracking
            },
            
            # Context metadata
            "context": {
                "schema_context_size": len(str(schema_context)),
                "nlp_insights_used": bool(enhanced_context and enhanced_context.get('nlp_optimization')),
                "optimization_applied": True,
                "prompt_source": "centralized_bridge" if self.nlp_schema_bridge else "fallback"
            }
        }

    # CACHING METHODS (kept - not duplicated elsewhere)

    def _generate_cache_key(self, query: str, context: Optional[Dict[str, Any]]) -> str:
        """Generate cache key including NLP context for accuracy"""
        base_key = query.lower().strip()
        
        if context and context.get('nlp_optimization'):
            nlp_opt = context['nlp_optimization']
            context_key = f"{nlp_opt.get('simplified_intent', '')}-{'-'.join(nlp_opt.get('key_entities', [])[:3])}"
            combined_key = f"{base_key}-{context_key}"
        else:
            combined_key = base_key
        
        return hashlib.md5(combined_key.encode()).hexdigest()[:16]  # Short hash for performance

    def _cache_result(self, key: str, result: Dict[str, Any]):
        """Cache result with TTL for performance"""
        if not self.config.enable_caching:
            return
        
        self.cache[key] = {
            "result": result,
            "timestamp": time.time()
        }
        
        # Simple cache cleanup (remove oldest if too large)
        if len(self.cache) > 100:
            oldest_key = min(self.cache.keys(), key=lambda k: self.cache[k]["timestamp"])
            del self.cache[oldest_key]

    def _get_cached_result(self, key: str) -> Optional[Dict[str, Any]]:
        """Get cached result with TTL check"""
        if not self.config.enable_caching:
            return None
        
        cache_entry = self.cache.get(key)
        if not cache_entry:
            return None
        
        # Check TTL
        if time.time() - cache_entry["timestamp"] > self.config.cache_ttl:
            del self.cache[key]
            return None
        
        return cache_entry["result"]

    def _add_metadata(
        self, 
        result: Dict[str, Any], 
        start_time: float, 
        request_id: str, 
        cached: bool = False
    ) -> Dict[str, Any]:
        """Add consistent metadata to results"""
        result["request_id"] = request_id
        result["manager"] = "traditional"
        result["cached"] = cached
        
        if not cached:
            result["processing_time"] = time.time() - start_time
        
        return result

    # MONITORING AND HEALTH

    async def health_check(self) -> Dict[str, Any]:
        """Comprehensive health check"""
        try:
            component_health = {
                "schema_engine": self.schema_engine is not None,
                "nlp_schema_bridge": self.nlp_schema_bridge is not None,  # NEW
                "centralized_prompt_builder": self.nlp_schema_bridge is not None,  # NEW
                "async_client_manager": self.async_client_manager is not None,  # ðŸ”§ NEW: Added status
                "sql_generator": self.sql_generator is not None,
                "sql_executor": self.sql_executor is not None
            }
            
            all_healthy = all(component_health.values())
            
            return {
                "component": "TraditionalManager",
                "version": "2.1.1",
                "status": "healthy" if all_healthy else "degraded",
                "timestamp": time.time(),
                "components": component_health,
                "performance_stats": self.performance_stats,
                "cache_stats": {
                    "cache_enabled": self.config.enable_caching,
                    "cache_size": len(self.cache),
                    "cache_hit_rate": (
                        self.performance_stats["cache_hits"] / 
                        max(self.performance_stats["total_queries"], 1)
                    ) * 100
                },
                "configuration": {
                    "max_processing_time": self.config.max_processing_time,
                    "nlp_enhancement_enabled": self.config.enable_nlp_enhancement,
                    "max_schema_results": self.config.max_schema_results
                },
                
                # NEW: Architecture info
                "architecture": {
                    "duplicate_prompt_assembler_removed": True,
                    "uses_centralized_bridge": self.nlp_schema_bridge is not None,
                    "no_code_duplication": True,
                    "centralized_integration": True,
                    "performance_optimized": True,
                    "parameter_mismatch_fixed": True  # ðŸ”§ NEW: Confirmation of fix
                }
            }
            
        except Exception as e:
            return {
                "component": "TraditionalManager",
                "version": "2.1.1",
                "status": "error",
                "error": str(e),
                "timestamp": time.time()
            }

    async def cleanup(self):
        """Cleanup resources and reset stats"""
        self.cache.clear()
        self.performance_stats = {
            "total_queries": 0,
            "cache_hits": 0,
            "successful_queries": 0,
            "failed_queries": 0,
            "average_processing_time": 0.0,
            "nlp_enhanced_queries": 0
        }
        logger.info("Traditional Manager cleaned up successfully")

# COMPATIBILITY FUNCTIONS FOR ORCHESTRATOR

async def process_traditional_query_async(query: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    """Async compatibility function for orchestrator"""
    manager = TraditionalManager()
    return await manager.process_query(query, context)

def orchestrate_traditional_query(query: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    """Sync compatibility function for orchestrator"""
    import asyncio
    try:
        loop = asyncio.get_event_loop()
        return loop.run_until_complete(process_traditional_query_async(query, context))
    except RuntimeError:
        # Create new event loop if none exists
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            return loop.run_until_complete(process_traditional_query_async(query, context))
        finally:
            loop.close()

# ðŸ”§ FIXED: Factory Functions with AsyncClientManager parameter

def create_traditional_manager(
    config: Optional[TraditionalManagerConfig] = None, 
    nlp_schema_bridge=None, 
    async_client_manager=None  # ðŸ”§ FIXED: Added missing parameter
) -> TraditionalManager:
    """
    FIXED: Factory function for creating Traditional Manager with centralized bridge support
    Now accepts async_client_manager parameter to eliminate parameter mismatch warnings
    """
    return TraditionalManager(config, nlp_schema_bridge, async_client_manager)

# EXPORTS

__all__ = [
    'TraditionalManager', 
    'TraditionalManagerConfig', 
    'create_traditional_manager',
    'orchestrate_traditional_query',
    'process_traditional_query_async'
]

if __name__ == "__main__":
    # Test the manager
    async def test():
        config = TraditionalManagerConfig(enable_performance_monitoring=True)
        manager = create_traditional_manager(config)
        
        # Test query with NLP context
        query = "Show customer account information"
        enhanced_context = {
            'nlp_optimization': {
                'simplified_intent': 'simple_lookup',
                'key_entities': ['customer', 'account'],
                'fast_processing': True
            }
        }
        
        result = await manager.process_query(query, enhanced_context)
        print(f"Success: {result['success']}")
        print(f"Processing Time: {result.get('processing_time', 0):.3f}s")
        print(f"Centralized Bridge Used: {result['context']['prompt_source'] == 'centralized_bridge'}")
        print(f"AsyncClientManager Available: {result['performance']['async_client_manager_available']}")
        
        # Test health check
        health = await manager.health_check()
        print(f"Health Status: {health['status']}")
        print(f"Centralized Bridge: {health['components']['nlp_schema_bridge']}")
        print(f"AsyncClientManager: {health['components']['async_client_manager']}")
        print(f"Parameter Mismatch Fixed: {health['architecture']['parameter_mismatch_fixed']}")
        print(f"No Duplication: {health['architecture']['no_code_duplication']}")
        
        await manager.cleanup()
        
        print("CENTRALIZED TRADITIONAL MANAGER - PARAMETER WARNINGS FIXED!")

    import asyncio
    asyncio.run(test())
